{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "489b9f0a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "489b9f0a",
    "outputId": "c196d9cc-6f28-4b63-d56a-d7584b0f746a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pshen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string \n",
    "import re\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from random import randint\n",
    "nltk.download('punkt')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import Model \n",
    "\n",
    "from tensorflow.keras.layers import (LSTM,\n",
    "                                     GRU, \n",
    "                                     Embedding, \n",
    "                                     Dense, \n",
    "                                     Input,\n",
    "                                     AdditiveAttention,\n",
    "                                     Layer)\n",
    "from tensorflow import ones, shape\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77761359",
   "metadata": {
    "id": "77761359"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''Clean text by removing unnecessary characters and altering the format of words.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"it's\", \"it is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"that is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"how's\", \"how is\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"n'\", \"ng\", text)\n",
    "    text = re.sub(r\"'bout\", \"about\", text)\n",
    "    text = re.sub(r\"'til\", \"until\", text)\n",
    "    text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|]\", \"\", text)\n",
    "    text = \" \".join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c49ba7b",
   "metadata": {
    "id": "5c49ba7b"
   },
   "outputs": [],
   "source": [
    "with open('./ChatBot_Dataset/movie_lines.txt', 'r', encoding='cp1252') as movie_lines:\n",
    "    lines = movie_lines.read().split('\\n')\n",
    "    \n",
    "movie_line_dict = {}\n",
    "for line in lines:\n",
    "    text = line.split(' +++$+++ ')[-1]\n",
    "    index = line.split(' +++$+++ ')[0]\n",
    "    clean_line = clean_text(text)\n",
    "    tokinized_text = nltk.word_tokenize(clean_line)\n",
    "    movie_line_dict[index] = tokinized_text\n",
    "        \n",
    "\n",
    "with open('./ChatBot_Dataset/movie_conversations.txt', 'r', encoding='cp1252') as movie_conversation:\n",
    "    lines = movie_conversation.read().split('\\n')\n",
    "movie_conversation_list = [line.split(' +++$+++ ')[-1][1:-1].replace(\"'\", '').split(', ') for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aab138e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input, decoder_input, decoder_target  = [], [], []\n",
    "\n",
    "for conv in movie_conversation_list:\n",
    "    for line in range(len(conv)-1): \n",
    "        encoder_input.append(movie_line_dict[conv[line]])\n",
    "        decoder_input.append(movie_line_dict[conv[line+1]])\n",
    "        decoder_target.append(movie_line_dict[conv[line+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdafbe30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 percentile of encoder length sequances = 6.0\n",
      "30 percentile of encoder length dequances = 6.0\n",
      "\n",
      "40 percentile of encoder length sequances = 7.0\n",
      "40 percentile of encoder length dequances = 7.0\n",
      "\n",
      "80 percentile of encoder length sequances = 19.0\n",
      "80 percentile of encoder length dequances = 19.0\n",
      "\n",
      "90 percentile of encoder length sequances = 27.0\n",
      "90 percentile of encoder length dequances = 29.0\n",
      "\n",
      "sample shape encoder input = 148465\n",
      "sample shape decoder input = 148465\n",
      "sample shape decoder target = 148465\n"
     ]
    }
   ],
   "source": [
    "len_seq_enc = [len(seq) for seq in encoder_input]\n",
    "len_seq_dec = [len(seq) for seq in decoder_input]\n",
    "\n",
    "for percentile in [30, 40, 80, 90]:\n",
    "    print('{} percentile of encoder length sequances = {}'.\n",
    "          format(percentile, np.percentile(len_seq_enc, percentile)))\n",
    "    print('{} percentile of encoder length dequances = {}'.\n",
    "          format(percentile, np.percentile(len_seq_dec, percentile)), end = '\\n\\n')\n",
    "    \n",
    "enc_inp_trimmed, dec_inp_trimmed, dec_tar_trimmed = [], [], []\n",
    "\n",
    "MIN_SEQ_LEN = 2\n",
    "MAX_SEQ_LEN = 20\n",
    "\n",
    "for i in range(len(encoder_input)):\n",
    "    if (len(encoder_input[i]) >= MIN_SEQ_LEN and len(encoder_input[i]) <= MAX_SEQ_LEN)\\\n",
    "    and (len(decoder_input[i]) >= MIN_SEQ_LEN and len(decoder_input[i]) <= MAX_SEQ_LEN):\n",
    "        enc_inp_trimmed.append(encoder_input[i])\n",
    "        dec_inp_trimmed.append(decoder_input[i])\n",
    "        dec_tar_trimmed.append(decoder_target[i])\n",
    "\n",
    "\n",
    "print(f'sample shape encoder input = {len(enc_inp_trimmed)}')\n",
    "print(f'sample shape decoder input = {len(dec_inp_trimmed)}')\n",
    "print(f'sample shape decoder target = {len(dec_tar_trimmed)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "816d3d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 30000\n",
    "\n",
    "result_enc_inp = enc_inp_trimmed[:num_samples]\n",
    "result_dec_inp = dec_inp_trimmed[:num_samples]\n",
    "result_dec_tar = dec_tar_trimmed[:num_samples]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b751fd4b",
   "metadata": {
    "id": "b751fd4b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent 80 = 7.0\n",
      "percent 85 = 10.0\n",
      "percent 90 = 17.0\n",
      "percent 95 = 42.0\n",
      "percent 98 = 144.42000000000007\n",
      "percent 99 = 353.8399999999965\n",
      "\n",
      "=====================================================\n",
      "Vocab element exaple: \n",
      "<START>\n",
      "<PAD>\n",
      "<UNK>\n",
      "<FINISH>\n",
      ".\n",
      "?\n",
      "\n",
      "=====================================================\n",
      "Total vocab size = 1410\n"
     ]
    }
   ],
   "source": [
    "words = list(itertools.chain(*list(result_enc_inp), *list(result_dec_inp)))\n",
    "value, count = np.unique(words, return_counts = True)\n",
    "word_df = pd.DataFrame({'value': value, 'count': count})\n",
    "word_df.sort_values('count', ascending = False, inplace = True)\n",
    "\n",
    "\n",
    "for percentile in [80, 85, 90, 95, 98, 99]:\n",
    "    print('percent {} = {}'.format(percentile, np.percentile(word_df['count'], percentile)))\n",
    "    \n",
    "threshold = 18\n",
    "\n",
    "word_for_vocab = word_df[word_df['count'] > threshold]['value'].values\n",
    "vocab = {item: num+4 for num, item in enumerate(word_for_vocab)}\n",
    "vocab['<START>'] = 0\n",
    "vocab['<PAD>'] = 1\n",
    "vocab['<UNK>'] = 2\n",
    "vocab['<FINISH>'] = 3\n",
    "\n",
    "VOCAB_SIZE = len(vocab)\n",
    "\n",
    "print('\\n=====================================================\\nVocab element exaple: ')\n",
    "\n",
    "inv_vocab = {num: item for item, num in vocab.items()}\n",
    "for i in range(6):\n",
    "    print(inv_vocab[i])\n",
    "    \n",
    "print(f'\\n=====================================================\\nTotal vocab size = {VOCAB_SIZE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d9d5e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def char2idx(conv: list, inp = False, tar = False):\n",
    "    \n",
    "    if inp:\n",
    "        return np.array([0] + [2 if elem not in vocab.keys() else vocab[elem] for elem in conv])\n",
    "    \n",
    "    if tar:\n",
    "        return np.array([2 if elem not in vocab.keys() else vocab[elem] for elem in conv] + [3])\n",
    "    \n",
    "    return np.array([2 if elem not in vocab.keys() else vocab[elem] for elem in conv])\n",
    "\n",
    "def idx2char(conv):\n",
    "    return ['<UNK>' if elem not in inv_vocab.keys() else inv_vocab[elem] for elem in conv]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51d893d3",
   "metadata": {
    "id": "51d893d3"
   },
   "outputs": [],
   "source": [
    "result_enc_inp_idx = [char2idx(conv) for conv in result_enc_inp]\n",
    "result_dec_inp_idx = [char2idx(conv, inp=True) for conv in result_dec_inp]\n",
    "result_dec_tar_idx = [char2idx(conv, tar=True) for conv in result_dec_tar]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4272290",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_input_seqs:\n",
      " ['well', ',', 'i', 'thought', 'we', 'would', 'start', 'with', '<UNK>', ',', 'if', 'that', 'is', 'okay', 'with', 'you', '.']\n",
      "==============================\n",
      "decoder_input_seqs:\n",
      " ['<START>', 'not', 'the', '<UNK>', 'and', '<UNK>', 'and', '<UNK>', 'part', '.', 'please', '.']\n",
      "==============================\n",
      "decoder_target_seqs:\n",
      " ['not', 'the', '<UNK>', 'and', '<UNK>', 'and', '<UNK>', 'part', '.', 'please', '.', '<FINISH>']\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "print('encoder_input_seqs:\\n', idx2char(result_enc_inp_idx[0]), end = '\\n==============================\\n')\n",
    "print('decoder_input_seqs:\\n', idx2char(result_dec_inp_idx[0]), end = '\\n==============================\\n')\n",
    "print('decoder_target_seqs:\\n', idx2char(result_dec_tar_idx[0]), end = '\\n==============================\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4152b458",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4152b458",
    "outputId": "2fa1f4f7-835a-428d-a84d-5402defab71e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_input_seqs shape:  (30000, 20)\n",
      "decoder_input_seqs shape:  (30000, 20)\n",
      "decoder_target_seqs shape:  (30000, 20)\n"
     ]
    }
   ],
   "source": [
    "encoder_input_seqs = pad_sequences(\n",
    "    result_enc_inp_idx,\n",
    "    value=vocab['<PAD>'],\n",
    "    padding='post',\n",
    "    truncating='post',\n",
    "    maxlen=MAX_SEQ_LEN)\n",
    "\n",
    "decoder_input_seqs = pad_sequences(\n",
    "    result_dec_inp_idx,\n",
    "    value=vocab['<PAD>'],\n",
    "    padding='post',\n",
    "    truncating='post',\n",
    "    maxlen=MAX_SEQ_LEN)\n",
    "\n",
    "decoder_target_seqs = pad_sequences(\n",
    "    result_dec_tar_idx,\n",
    "    value=vocab['<PAD>'],\n",
    "    padding='post',\n",
    "    truncating='post',\n",
    "    maxlen=MAX_SEQ_LEN)\n",
    "\n",
    "\n",
    "print('encoder_input_seqs shape: ', encoder_input_seqs.shape)\n",
    "print('decoder_input_seqs shape: ', decoder_input_seqs.shape)\n",
    "print('decoder_target_seqs shape: ', decoder_target_seqs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "070227df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "070227df",
    "outputId": "fb380104-7c76-4074-cc4b-fc9cb3c973fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_input_seqs:\n",
      " ['hi', '.', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "==============================\n",
      "decoder_input_seqs:\n",
      " ['<START>', 'looks', 'like', 'things', 'worked', 'out', 'tonight', ',', 'huh', '?', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "==============================\n",
      "decoder_target_seqs:\n",
      " ['looks', 'like', 'things', 'worked', 'out', 'tonight', ',', 'huh', '?', '<FINISH>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "print('encoder_input_seqs:\\n', idx2char(encoder_input_seqs[10]), end = '\\n==============================\\n')\n",
    "print('decoder_input_seqs:\\n', idx2char(decoder_input_seqs[10]), end = '\\n==============================\\n')\n",
    "print('decoder_target_seqs:\\n', idx2char(decoder_target_seqs[10]), end = '\\n==============================\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "E-pKhPjKSlJH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E-pKhPjKSlJH",
    "outputId": "1f61ac65-1c7c-4db6-9757-c0d16860e60c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enx_train shape:  (27000, 20)\n",
      "enx_val shape:  (3000, 20)\n",
      "dec_tar_train shape:  (27000, 20)\n",
      "dec_tar_val shape:  (3000, 20)\n",
      "dec_inp_train shape:  (27000, 20)\n",
      "dec_inp_train shape:  (27000, 20)\n"
     ]
    }
   ],
   "source": [
    "enc_train, enc_val, dec_tar_train, dec_tar_val, dec_inp_train, dec_inp_val = train_test_split(\n",
    "    *(encoder_input_seqs, decoder_target_seqs, decoder_input_seqs),\n",
    "    train_size = 0.9)\n",
    "\n",
    "print('enx_train shape: ', enc_train.shape)\n",
    "print('enx_val shape: ', enc_val.shape)\n",
    "print('dec_tar_train shape: ', dec_tar_train.shape)\n",
    "print('dec_tar_val shape: ', dec_tar_val.shape)\n",
    "print('dec_inp_train shape: ', dec_inp_train.shape)\n",
    "print('dec_inp_train shape: ', dec_inp_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7070d86",
   "metadata": {
    "id": "e7070d86"
   },
   "outputs": [],
   "source": [
    "EMB_SIZE = 256\n",
    "H_SIZE = 512\n",
    "\n",
    "\n",
    "class Encoder(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb = Embedding(VOCAB_SIZE, EMB_SIZE)\n",
    "        self.lstm = LSTM(H_SIZE, return_sequences = False, return_state = True)\n",
    "\n",
    "    def call(self, inp):\n",
    "        out = self.emb(inp)\n",
    "        _, h, c = self.lstm(out)\n",
    "        return (h, c)\n",
    "    \n",
    "class Decoder(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb = Embedding(VOCAB_SIZE, EMB_SIZE)\n",
    "        self.lstm = LSTM(H_SIZE, return_sequences = True, return_state = True)\n",
    "        self.fc = Dense(VOCAB_SIZE, activation = 'softmax')\n",
    "        \n",
    "    def call(self, inp, init_state):\n",
    "        out = self.emb(inp)\n",
    "        out, h, c = self.lstm(out, initial_state = init_state)\n",
    "        out = self.fc(out)\n",
    "        return out, (h, c)\n",
    "    \n",
    "def build_model():\n",
    "    \n",
    "    encoder = Encoder()\n",
    "    decoder = Decoder()\n",
    "\n",
    "\n",
    "    encoder_inputs = Input(shape = (None,) )\n",
    "    decoder_inputs = Input(shape = (None,) )\n",
    "\n",
    "    enc_state = encoder(encoder_inputs)\n",
    "    decoder_outputs, _ = decoder(decoder_inputs, enc_state)\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    model.compile(loss = loss, optimizer = optimizer, metrics = ['accuracy'])\n",
    "    \n",
    "\n",
    "    return (model,encoder,decoder)\n",
    "\n",
    "model, _, _ = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75c97c70",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "75c97c70",
    "outputId": "579cdda3-0183-4722-8092-b06dc664c524"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "EPOCHs = 150\n",
    "\n",
    "checkpoint_filepath = './model/auto_checkpoint/'\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    save_freq = 10,)\n",
    "\n",
    "loss = SparseCategoricalCrossentropy()\n",
    "optimizer = Adam(learning_rate = .003)\n",
    "\n",
    "model.fit([enc_train, dec_inp_train], \n",
    "          dec_tar_train,\n",
    "          epochs = EPOCHs, \n",
    "          validation_data=([enc_val, dec_inp_val], dec_tar_val),\n",
    "          batch_size = BATCH_SIZE)\n",
    "model.save_weights('./model/weights.h5', save_format = 'h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "PWl3RsW_hzRK",
   "metadata": {
    "id": "PWl3RsW_hzRK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 23s 203ms/step - loss: 0.5458 - accuracy: 0.9363\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5457586050033569, 0.9363166689872742]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, encoder, decoder = build_model()\n",
    "model.load_weights('./model/weights.h5')\n",
    "model.evaluate([enc_val, dec_inp_val], dec_tar_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75b82f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_inference(input_seq):\n",
    "    state = encoder(input_seq)\n",
    "\n",
    "    target_seq = np.array([[vocab['<START>']]])\n",
    "\n",
    "    decoded_sentence = ''\n",
    "    decode_count = 0\n",
    "    while True:\n",
    "        output_tokens, state = decoder(target_seq, state)\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = inv_vocab[sampled_token_index]\n",
    "        decoded_sentence += sampled_char + ' '\n",
    "        decode_count += 1\n",
    "\n",
    "\n",
    "        if (sampled_char == '<FINISH>' or\n",
    "           decode_count > MAX_SEQ_LEN):\n",
    "              break\n",
    "\n",
    "        target_seq = np.array([[sampled_token_index]])\n",
    "\n",
    "    return ''.join(decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "928ef0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: your men knew the risks .\n",
      "Result sentence: what is going on here , man ? <FINISH> \n",
      "Target sentence: what is going on here , man ?\n",
      "-\n",
      "Input sentence: with my money !\n",
      "Result sentence: we should not have done that . <FINISH> \n",
      "Target sentence: we should go burn that school to the ground , sir !\n",
      "-\n",
      "Input sentence: the final route for the railroad is complete .\n",
      "Result sentence: call me <UNK> . <FINISH> \n",
      "Target sentence: i look forward to seeing it .\n",
      "-\n",
      "Input sentence: parker .\n",
      "Result sentence: <UNK> . <FINISH> \n",
      "Target sentence: sir ?\n",
      "-\n",
      "Input sentence: sir ?\n",
      "Result sentence: <UNK> ! look ! the <UNK> 's <UNK> <UNK> . he is up back to the <UNK> . <FINISH> \n",
      "Target sentence: what is that ?\n",
      "-\n",
      "Input sentence: what is that ?\n",
      "Result sentence: no there are <UNK> to see what we are going to do better . <FINISH> \n",
      "Target sentence: what , sir ?\n",
      "-\n",
      "Input sentence: that .\n",
      "Result sentence: you are clean . <FINISH> \n",
      "Target sentence: oh , that . i will let jenkins explain .\n",
      "-\n",
      "Input sentence: this is him .\n",
      "Result sentence: i remember you . <FINISH> \n",
      "Target sentence: i remember you .\n",
      "-\n",
      "Input sentence: how did you know ?\n",
      "Result sentence: not such a <UNK> now , is he , <UNK> ? <FINISH> \n",
      "Target sentence: not such a menace now , is he , pinkerton ?\n",
      "-\n",
      "Input sentence: this is no game .\n",
      "Result sentence: i am afraid our <UNK> do not agree . <FINISH> \n",
      "Target sentence: i am afraid our adversaries do not agree .\n",
      "-\n",
      "Input sentence: so you can not tell me anything ?\n",
      "Result sentence: it is going to be a long <UNK> . <FINISH> \n",
      "Target sentence: it is going to be a long winter .\n",
      "-\n",
      "Input sentence: i can not believe this .\n",
      "Result sentence: <UNK> spoke . this <UNK> will be part of the lord ever <UNK> . <FINISH> \n",
      "Target sentence: and there are some towns in missouri where james and his men can walk openly , as heroes .\n",
      "-\n",
      "Input sentence: yes , that is the way to win the locals back to our side .\n",
      "Result sentence: i <UNK> <UNK> . <FINISH> \n",
      "Target sentence: i demand action .\n",
      "-\n",
      "Input sentence: can not you tell me anything ?\n",
      "Result sentence: it is going to be a long <UNK> . <FINISH> \n",
      "Target sentence: it is going to be a long spring .\n",
      "-\n",
      "Input sentence: so he is won .\n",
      "Result sentence: no . <FINISH> \n",
      "Target sentence: no .\n"
     ]
    }
   ],
   "source": [
    "i = randint(0, 30000)\n",
    "for seq_index in range(i, i+15):\n",
    "    input_seq = encoder_input_seqs[seq_index: seq_index + 1]\n",
    "    decoded_sentence = seq2seq_inference(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', ' '.join(result_enc_inp[seq_index]))\n",
    "    print('Result sentence:', decoded_sentence)\n",
    "    print('Target sentence:', ' '.join(result_dec_tar[seq_index]))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chatbot.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
